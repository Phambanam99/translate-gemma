# ğŸ³ TranslateGemma Docker Quick Start

## âš¡ Khá»Ÿi Ä‘á»™ng nhanh (30 giÃ¢y)

```bash
# 1. Má»™t lá»‡nh Ä‘á»ƒ khá»Ÿi Ä‘á»™ng táº¥t cáº£ (GPU 2)
bash docker-start.sh 2

# 2. Truy cáº­p:
# - Frontend: http://localhost
# - API: http://localhost:8000/docs
```

## ğŸ“‹ YÃªu cáº§u

ÄÃ£ cÃ i Ä‘áº·t:
- âœ… Docker & Docker Compose
- âœ… NVIDIA Docker Runtime
- âœ… GPU NVIDIA (A100)
- âœ… CUDA 13.1+

## ğŸš€ 3 CÃ¡ch cháº¡y

### CÃ¡ch 1: Script (Khuyáº¿n nghá»‹)
```bash
# GPU 2 (máº·c Ä‘á»‹nh, ~79GB free)
bash docker-start.sh 2

# Hoáº·c GPU khÃ¡c
bash docker-start.sh 0
bash docker-start.sh 1
bash docker-start.sh 3
```

### CÃ¡ch 2: Docker Compose trá»±c tiáº¿p
```bash
# Cháº¡y vá»›i GPU 2
GPU_DEVICE_ID=2 CUDA_VISIBLE_DEVICES=2 docker compose up -d

# Cháº¡y vá»›i GPU 0
GPU_DEVICE_ID=0 CUDA_VISIBLE_DEVICES=0 docker compose up -d
```

### CÃ¡ch 3: Sá»­a .env.docker
```bash
# 1. Sá»­a .env.docker
vim .env.docker
# GPU_DEVICE_ID=2  <- thay Ä‘á»•i sá»‘ nÃ y

# 2. Khá»Ÿi Ä‘á»™ng
docker compose up -d
```

## ğŸ“ Äá»‹a chá»‰ truy cáº­p

| Dá»‹ch vá»¥ | Äá»‹a chá»‰ | MÃ´ táº£ |
|---------|---------|-------|
| **Frontend** | http://localhost | Giao diá»‡n web React |
| **Backend API** | http://localhost:8000 | REST API |
| **API Documentation** | http://localhost:8000/docs | Swagger UI |
| **GPU Info** | `docker exec translate-gemma-backend nvidia-smi` | Kiá»ƒm tra GPU |

## ğŸ® Kinh nghiÃªm quÃ½ bÃ¡u vá» GPU 2

Báº¡n cÃ³ **4 GPUs A100 80GB**:

```
GPU 0: 75,499 MiB used / 81,920 MiB total  âŒ (93% sá»­ dá»¥ng)
GPU 1: 20,433 MiB used / 81,920 MiB total  âš ï¸  (25% sá»­ dá»¥ng)
GPU 2:  2,335 MiB used / 81,920 MiB total  âœ… (3% sá»­ dá»¥ng)  â† BEST
GPU 3: 21,921 MiB used / 81,920 MiB total  âš ï¸  (27% sá»­ dá»¥ng)
```

**GPU 2 cÃ³ ~79GB available - Ä‘Ã¢y lÃ  lá»±a chá»n tá»‘i Æ°u!**

## ğŸ“Š Kiá»ƒm tra tráº¡ng thÃ¡i

```bash
# Xem status cÃ¡c container
docker compose ps

# Xem logs backend (GPU loading, model...)
docker compose logs -f backend

# Xem logs frontend
docker compose logs -f frontend

# Kiá»ƒm tra GPU Ä‘ang sá»­ dá»¥ng
docker exec translate-gemma-backend nvidia-smi

# Theo dÃµi real-time
watch -n 1 'docker exec translate-gemma-backend nvidia-smi'
```

## ğŸ›‘ Dá»«ng dá»‹ch vá»¥

```bash
# CÃ¡ch nhanh nháº¥t
bash docker-stop.sh

# Hoáº·c dÃ¹ng docker compose
docker compose down

# Náº¿u muá»‘n xÃ³a táº¥t cáº£ dá»¯ liá»‡u (cáº£nh bÃ¡o!)
docker compose down -v
```

## ğŸ”§ Troubleshooting

### âŒ GPU khÃ´ng Ä‘Æ°á»£c nháº­n diá»‡n

```bash
# Kiá»ƒm tra NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:12.4.1-base nvidia-smi

# Náº¿u lá»—i, cÃ i Ä‘áº·t NVIDIA Container Toolkit
curl https://get.docker.com | bash

sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

### âŒ Out of Memory

```bash
# Náº¿u GPU 2 full, thá»­ GPU 1 (25% sá»­ dá»¥ng)
GPU_DEVICE_ID=1 CUDA_VISIBLE_DEVICES=1 docker compose up -d

# Hoáº·c tÄƒng memory limit
docker compose down
# Sá»­a docker-compose.yml: mem_limit: 256g
docker compose up -d
```

### âŒ Model khÃ´ng download Ä‘Æ°á»£c

```bash
# CÃ¡ch 1: Download trÆ°á»›c trÃªn host
cd backend
python3 download_model.py

# CÃ¡ch 2: DÃ¹ng cached model tá»« host
# Sá»­a docker-compose.yml:
# volumes:
#   - ~/.cache/huggingface:/app/model_cache
docker compose up -d
```

### âŒ Port Ä‘Ã£ bá»‹ sá»­ dá»¥ng

```bash
# TÃ¬m process chiáº¿m port 80 hoáº·c 8000
sudo lsof -i :80
sudo lsof -i :8000

# Kill process hoáº·c thay port trong docker-compose.yml
```

## ğŸ“ˆ Monitor GPU vÃ  Memory

```bash
# Xem memory GPU kháº£ dá»¥ng (trá»±c tiáº¿p)
docker exec translate-gemma-backend nvidia-smi --query-gpu=memory.free --format=csv

# Xem CPU/Memory cá»§a container
docker stats translate-gemma-backend

# Follow logs vá»›i timestamp
docker compose logs --timestamps -f backend
```

## ğŸ” Cáº¥u hÃ¬nh Hugging Face Token (tÃ¹y chá»n)

```bash
# 1. Táº¡o .env file
cat > .env << EOF
GPU_DEVICE_ID=2
CUDA_VISIBLE_DEVICES=2
HF_TOKEN=hf_xxxxxxxxxxxxx
EOF

# 2. Khá»Ÿi Ä‘á»™ng
docker compose up -d
```

## ğŸ“¦ Build láº¡i images

Náº¿u báº¡n sá»­a code:

```bash
# Build láº¡i
docker compose build --no-cache

# Hoáº·c xÃ³a images vÃ  build láº¡i
docker rmi translate-gemma:latest-backend translate-gemma:latest-frontend
docker compose build
```

## ğŸŒ Cháº¡y trÃªn Host khÃ¡c (Production)

1. **Copy code**
```bash
scp -r translate-gemma user@remote-host:/opt/
```

2. **SSH vÃ o host**
```bash
ssh user@remote-host
cd /opt/translate-gemma
```

3. **Khá»Ÿi Ä‘á»™ng vá»›i GPU khÃ¡c (náº¿u cáº§n)**
```bash
bash docker-start.sh 3  # Hoáº·c sá»‘ GPU khÃ¡c
```

## ğŸ’¡ Tips & Tricks

```bash
# Khá»Ÿi Ä‘á»™ng láº¡i container
docker compose restart backend

# Cháº¡y lá»‡nh trong container
docker compose exec backend bash

# Xem táº¥t cáº£ volumes
docker volume ls | grep translate

# Xem kÃ­ch thÆ°á»›c volumes
docker volume inspect translate-gemma_model_cache
du -sh /var/lib/docker/volumes/translate-gemma_model_cache/_data

# Clean up unused images/volumes
docker system prune
docker volume prune
```

## ğŸ“š Chi tiáº¿t hÆ¡n

Xem [DOCKER_DEPLOYMENT.md](./DOCKER_DEPLOYMENT.md) Ä‘á»ƒ cÃ³:
- CÃ i Ä‘áº·t chi tiáº¿t NVIDIA Docker
- Cáº¥u hÃ¬nh HTTPS/Nginx
- Performance tuning
- Build production images
- VÃ  nhiá»u hÆ¡n ná»¯a...

## ğŸ†˜ Cáº§n giÃºp thÃªm?

```bash
# Xem full logs
docker compose logs backend | tail -200

# Xem error tá»« model loading
docker compose logs backend | grep -i "error\|failed\|exception"

# Kiá»ƒm tra káº¿t ná»‘i API
curl http://localhost:8000/api/health
```

---

**Máº¹o:** Náº¿u muá»‘n dÃ¹ng GPU khÃ¡c, thay `2` báº±ng sá»‘ GPU cáº§n dÃ¹ng (0, 1, 3, ...) á»Ÿ má»i chá»—.
